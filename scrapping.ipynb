{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire : \n",
    "- indexer les articles (et indice inversé)\n",
    "- changer les noms des fichiers json pour qu'ils soient appelés par leur titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "    user_agent='MyProjectName',\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Get data for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def url_categorymembers(categorymembers,list_pages=[], level=0, max_level=3, i=0):\n",
    "    pages_cat = list(categorymembers.values()) #toutes les pages de la catégorie\n",
    "\n",
    "    shuffle(pages_cat)\n",
    "    print(i)\n",
    "\n",
    "    for c in pages_cat:\n",
    "        if i==1000: #1000 pages par catégorie\n",
    "            break\n",
    "\n",
    "        if c.title[:6]!=\"Portal\" and c.title[:5]!=\"File:\" and c.title[:8]!=\"Category\": # vérifie que c'est bien un article\n",
    "            i+=1\n",
    "            #list_urls.append(c.fullurl)\n",
    "            #list_pages.append(c)\n",
    "            #list_pages.append(c.title)\n",
    "            d = {}\n",
    "            d[\"titre\"] = c.title\n",
    "            d[\"contenu\"] = c.text\n",
    "            d[\"liens\"] = list(c.links.keys())\n",
    "            list_pages.append(d)\n",
    "\n",
    "        if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level: # descend d'un niveau\n",
    "            i = url_categorymembers(c.categorymembers, list_pages, level=level + 1, max_level=max_level, i=i)[1]\n",
    "\n",
    "    return list_pages, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_arts = wiki_wiki.page(\"Category:The arts\") # Arts\n",
    "arts, _ = url_categorymembers(cat_arts.categorymembers)\n",
    "pd.DataFrame(arts).to_csv('arts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_games = wiki_wiki.page(\"Category:Games\") # Games\n",
    "games, _= url_categorymembers(cat_games.categorymembers)\n",
    "\n",
    "pd.DataFrame(games).to_csv('games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_youth = wiki_wiki.page(\"Category:Youth\") # Kids and Teens (not exact)\n",
    "youth, _ = url_categorymembers(cat_youth.categorymembers)\n",
    "\n",
    "pd.DataFrame(youth).to_csv('youth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_reference = wiki_wiki.page(\"Category:Reference\") # Reference\n",
    "reference, _ = url_categorymembers(cat_reference.categorymembers)\n",
    "\n",
    "pd.DataFrame(reference).to_csv('reference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_shopping = wiki_wiki.page(\"Category:Retailing\") # Shopping\n",
    "shopping, _ = url_categorymembers(cat_shopping.categorymembers)\n",
    "\n",
    "pd.DataFrame(shopping).to_csv('shopping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_business = wiki_wiki.page(\"Category:Business\") # Business\n",
    "business, _ = url_categorymembers(cat_business.categorymembers)\n",
    "\n",
    "pd.DataFrame(business).to_csv('business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_health = wiki_wiki.page(\"Category:Health\") # Health\n",
    "health, _ = url_categorymembers(cat_health.categorymembers)\n",
    "\n",
    "pd.DataFrame(health).to_csv('health.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_news = wiki_wiki.page(\"Category:News\") # News\n",
    "news, _ = url_categorymembers(cat_news.categorymembers)\n",
    "\n",
    "pd.DataFrame(news).to_csv('news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_geography = wiki_wiki.page(\"Category:Geography\") # Regional (not exact)\n",
    "geography, _ = url_categorymembers(cat_geography.categorymembers)\n",
    "\n",
    "pd.DataFrame(geography).to_csv('geography.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_society = wiki_wiki.page(\"Category:Society\") # Society\n",
    "society, _ = url_categorymembers(cat_society.categorymembers)\n",
    "\n",
    "pd.DataFrame(society).to_csv('society.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_computers = wiki_wiki.page(\"Category:Computers\") # Computers\n",
    "computers, _ = url_categorymembers(cat_computers.categorymembers)\n",
    "\n",
    "df = pd.DataFrame(computers)\n",
    "df.to_csv('computers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_home = wiki_wiki.page(\"Category:Home\") # Home\n",
    "home, _ = url_categorymembers(cat_home.categorymembers)\n",
    "\n",
    "df = pd.DataFrame(home)\n",
    "df.to_csv('home.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_recreation = wiki_wiki.page(\"Category:Recreation\") # Recreation\n",
    "recreation, _ = url_categorymembers(cat_recreation.categorymembers)\n",
    "\n",
    "pd.DataFrame(recreation).to_csv('recreation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_science = wiki_wiki.page(\"Category:Science\") # Science\n",
    "science, _ = url_categorymembers(cat_science.categorymembers)\n",
    "\n",
    "pd.DataFrame(science).to_csv('science.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sports = wiki_wiki.page(\"Category:Sports\") # Sports\n",
    "sports, _ = url_categorymembers(cat_sports.categorymembers)\n",
    "\n",
    "pd.DataFrame(sports).to_csv('sports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_world = wiki_wiki.page(\"Category:World\") # World\n",
    "world, _ = url_categorymembers(cat_world.categorymembers)\n",
    "\n",
    "pd.DataFrame(world).to_csv('world.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pas exécuté\n",
    "\n",
    "topics = {\n",
    "    \"Arts\": arts,\n",
    "    \"Games\": games,\n",
    "    \"Youth\": youth,\n",
    "    \"Reference\": reference, \n",
    "    \"Shopping\": shopping, \n",
    "    \"Business\": business, \n",
    "    \"Health\": health, \n",
    "    \"News\": news,\n",
    "    \"Geography\": geography,\n",
    "    \"Society\": society,\n",
    "    \"Computers\": computers,\n",
    "    \"Home\": home,\n",
    "    \"Recreation\": recreation,\n",
    "    \"Science\": science,\n",
    "    \"Sports\": sports,\n",
    "    \"World\": world\n",
    "}\n",
    "\n",
    "\n",
    "import pickle \n",
    "\n",
    "with open('titres_articles_categories.pkl', 'wb') as f:\n",
    "    pickle.dump(topics, f)\n",
    "        \n",
    "#with open('titres_articles_categories.pkl', 'rb') as f:\n",
    "    #topics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "csv_files = [\n",
    "    'arts.csv', 'business.csv', 'computers.csv', 'games.csv',\n",
    "    'geography.csv', 'health.csv', 'home.csv', 'news.csv',\n",
    "    'recreation.csv', 'reference.csv', 'science.csv', 'shopping.csv',\n",
    "    'society.csv', 'sports.csv', 'world.csv', 'youth.csv'\n",
    "]\n",
    "\n",
    "# Liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Lire chaque fichier CSV et l'ajouter à la liste des DataFrames\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(f'./Data/{file}')\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combiner tous les DataFrames en un seul\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Écrire le DataFrame combiné dans un nouveau fichier CSV\n",
    "combined_df.to_csv('./Data/all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Page Rank vectors (3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices d'adjacence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction de la matrice sans utiliser les fichiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "# build the adjacency matrix\n",
    "def build_adjacency_matrix_2(df): #pas optimisé\n",
    "    num_pages = df.shape[0]\n",
    "    adjacency_matrix = np.zeros((num_pages, num_pages))\n",
    "    df[\"liens\"] = df[\"liens\"].apply(ast.literal_eval)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        N = len(np.where(np.isin(row['liens'],df['titre'].values))[0]) # nombres de liens que fait la page\n",
    "        for link in row['liens']:\n",
    "            if link in df['titre'].values:\n",
    "                j = np.where(df['titre'] == link )[0]\n",
    "                adjacency_matrix[j,index] += 1/N\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "\n",
    "def build_adjacency_matrix(df):\n",
    "    df[\"liens\"] = df[\"liens\"].apply(ast.literal_eval)  # Convertir les liens de type string en listes\n",
    "\n",
    "    # Créer un dictionnaire pour mapper les titres aux indices\n",
    "    title_to_index = {title: i for i, title in enumerate(df['titre'])}\n",
    "    \n",
    "    # Initialiser la matrice d'adjacence avec des zéros\n",
    "    num_pages = len(df)\n",
    "    adjacency_matrix = np.zeros((num_pages, num_pages))\n",
    "    \n",
    "    # Construire une série pour mapper les liens aux indices\n",
    "    link_series = pd.Series(df['liens'].values.tolist())\n",
    "    link_indices = link_series.map(lambda x: [title_to_index[link] for link in x if link in title_to_index])\n",
    "    \n",
    "    # Compter le nombre de liens sortants pour chaque article\n",
    "    df['num_liens'] = link_indices.apply(len)\n",
    "    \n",
    "    for i, indices in enumerate(link_indices):\n",
    "        if len(indices)>0:\n",
    "            adjacency_matrix[indices, i] = 1 / df.at[i, 'num_liens']\n",
    "    \n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrice_all= build_adjacency_matrix(pd.read_csv('./Data/all.csv'))\n",
    "np.save('./Matrices/matrice_all.npy', matrice_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction de la matrice en utilisant les fichiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "fichier_graphe = pandas.read_csv('enwiki.wikilink_graph.2018-03-01.csv')\n",
    "\n",
    "# build the adjacency matrix\n",
    "def build_adjacency_matrix(topic_articles, inversed_index_articles):\n",
    "    num_pages = len(topic_articles)\n",
    "    adjacency_matrix = np.zeros((num_pages, num_pages))\n",
    "\n",
    "    for i,titre in enumerate(topic_articles):\n",
    "        #links = page_links(pages[i])\n",
    "        links = fichier_graphe[fichier_graphe['page_title_from']==titre]\n",
    "        for link in links:\n",
    "            if link in topic_articles:\n",
    "                j = topic_articles.index(link)\n",
    "                adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix/sum(adjacency_matrix,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute PageRank scores\n",
    "def compute_pagerank(M, alpha=0.25, bias = None): # bias = None pour page_rank normal, bias = topic sinon\n",
    "    # M = adjacency_matrix\n",
    "    # damping_factor = 1-alpha\n",
    "\n",
    "    N = M.shape[0]\n",
    "\n",
    "    if bias is None : # page_rank normal, pas topic_sensitive\n",
    "        p = np.ones(N) / N \n",
    "\n",
    "    else: # ODP-biasing \n",
    "        articles = pd.read_csv(f'./Data/all.csv')[\"titre\"].values\n",
    "        articles_cat = pd.read_csv(f'./Data/{bias}.csv')[\"titre\"].values\n",
    "        p = np.where(np.isin(articles,articles_cat), 1/len(articles_cat), 0)\n",
    "\n",
    "    #M_prime = (1-alpha) * M + alpha * teleportation_matrix\n",
    "\n",
    "    rank = np.ones(N) / N\n",
    "    old_rank = np.zeros(N)\n",
    "\n",
    "    epsilon = 1.0e-3\n",
    "    max_iterations = 10\n",
    "    iterations = 0\n",
    "\n",
    "    while np.sum(np.abs(rank - old_rank)) > epsilon and iterations < max_iterations:\n",
    "        old_rank = rank.copy()\n",
    "        rank = (1-alpha)*M @ rank + p # equation 5\n",
    "        #normaliser ?\n",
    "        iterations += 1\n",
    "\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:03:20.775110Z",
     "start_time": "2024-05-21T21:03:20.745248Z"
    }
   },
   "source": [
    "# Compute PageRank scores for each topic\n",
    "import numpy as np\n",
    "\n",
    "Topic_names = [\"arts\",\"games\",\"youth\",\"reference\", \"shopping\", \"business\", \"health\", \"news\",\"geography\",\"society\",\"computers\",\"home\",\"recreation\",\"science\",\"sports\",\"world\"]\n",
    "\n",
    "adjacency_matrix = np.load(f'./Matrices/matrice_all.npy')\n",
    "\n",
    "topic_pagerank = {}\n",
    "for topic in Topic_names:\n",
    "    #adjacency_matrix = np.load(f'./Matrices/matrice_{topic}.npy')\n",
    "    \n",
    "    pagerank_scores = compute_pagerank(adjacency_matrix,bias=topic)\n",
    "\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(pagerank_scores[:5])\n",
    "\n",
    "    topic_pagerank[topic] = pagerank_scores\n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Compute PageRank scores for each topic\u001B[39;00m\n\u001B[1;32m      3\u001B[0m Topic_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marts\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgames\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myouth\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreference\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshopping\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbusiness\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhealth\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnews\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeography\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msociety\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcomputers\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhome\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecreation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscience\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msports\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mworld\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m----> 5\u001B[0m adjacency_matrix \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./Matrices/matrice_all.npy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m topic_pagerank \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m topic \u001B[38;5;129;01min\u001B[39;00m Topic_names:\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;66;03m#adjacency_matrix = np.load(f'./Matrices/matrice_{topic}.npy')\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('topic_pagerank.pkl', 'wb') as fichier:\n",
    "    pickle.dump(topic_pagerank, fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.load(f'./Matrices/matrice_all.npy')\n",
    "pagerank_normal = compute_pagerank(adjacency_matrix,bias=None)\n",
    "with open('normal_pagerank.pkl', 'wb') as fichier:\n",
    "    pickle.dump(pagerank_normal, fichier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query-time importance score (3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "categories_text = {}\n",
    "for c in Topic_names:\n",
    "    liste_textes = pd.read_csv(f'./Data/{c}.csv')[\"contenu\"].values.astype(str)\n",
    "\n",
    "    texte = ' '.join(liste_textes)\n",
    "    categories_text[c] = texte\n",
    "\n",
    "D_categories = {}\n",
    "terms_indexes_categories = {}\n",
    "\n",
    "for c, text in categories_text.items():\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    D_categories[c] = vectorizer.fit_transform([text])\n",
    "    terms_indexes_categories[c] = vectorizer.get_feature_names_out()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('D.pkl', 'wb') as fichier:\n",
    "    pickle.dump(D_categories, fichier)\n",
    "\n",
    "with open('terms_indexes.pkl', 'wb') as fichier:\n",
    "    pickle.dump(terms_indexes_categories, fichier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T21:11:23.056539Z",
     "start_time": "2024-05-21T21:11:01.587187Z"
    }
   },
   "source": [
    "# Indexation des articles \n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
    "\n",
    "df = pd.read_csv(f'Data/all.csv')[[\"titre\",\"contenu\"]]\n",
    "df.columns = [\"docno\", \"text\"]\n",
    "\n",
    "pd_indexer = pt.DFIndexer(\"./pd_index\")\n",
    "indexref = pd_indexer.index(df[\"text\"], df[\"docno\"])\n",
    "index = pt.IndexFactory.of(indexref)\n",
    "\n",
    "Topic_names = [\"arts\",\"games\",\"youth\",\"reference\", \"shopping\", \"business\", \"health\", \"news\",\"geography\",\"society\",\"computers\",\"home\",\"recreation\",\"science\",\"sports\",\"world\"]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:06.130 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:06.258 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:06.335 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:06.348 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:06.356 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:08.741 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:09.447 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:09.543 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:10.272 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:10.716 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:11.010 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:11.029 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:11.182 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:12.433 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:14.395 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:14.617 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:14.660 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:14.836 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:15.367 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:15.467 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:16.835 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:18.876 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:18.951 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:18.990 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:18.996 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:11:19.576 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n",
      "23:11:19.688 [main] WARN org.terrier.structures.indexing.Indexer - skipping null document\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n",
      "Traceback (most recent call last):\n",
      "  File \"jnius/jnius_proxy.pxi\", line 50, in jnius.PythonJavaClass.invoke\n",
      "  File \"jnius/jnius_proxy.pxi\", line 76, in jnius.PythonJavaClass._invoke\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 778, in next\n",
      "    lastdoc = self.convertFn(text, meta)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyterrier/index.py\", line 687, in convertDoc\n",
      "    return TaggedDocument(StringReader(text_row), hashmap, Tokeniser.getTokeniser())\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"jnius/jnius_export_class.pxi\", line 269, in jnius.JavaClass.__init__\n",
      "  File \"jnius/jnius_export_class.pxi\", line 362, in jnius.JavaClass.call_constructor\n",
      "  File \"jnius/jnius_conversion.pxi\", line 74, in jnius.populate_args\n",
      "  File \"jnius/jnius_utils.pxi\", line 193, in jnius.check_assignable_from_str\n",
      "TypeError: Invalid instance of 'java/lang/Float' passed for a 'java/lang/String'\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:24:52.901623Z",
     "start_time": "2024-05-21T22:24:52.883962Z"
    }
   },
   "source": [
    "\n",
    "def sqd(q, topic_pagerank, D, terms_indexes, index):\n",
    "    # Using a text index, recuperer les docs qui contiennent q\n",
    "    br = pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\") # CoordinateMatch renvoie 1 si le terme est dans le doc, 0 sinon\n",
    "    docs_retrieved = br.search(q) # Renvoie le nombre de termes de la query qui sont dans chaque doc\n",
    "    docs_query = docs_retrieved[docs_retrieved[\"score\"] == len(q.split())]  # Garder uniquement les docs qui contiennent tous les termes de la query\n",
    "    docs_index = docs_query[\"docno\"].values\n",
    "    \n",
    "    # calculer P(cj|q)\n",
    "    probas_c_q = np.zeros((16))\n",
    "    p_c = 1/16 # \"The quantity P(cj) is not as straightforward. We chose to make it uniform\"\n",
    "\n",
    "    for i,topic in enumerate(Topic_names):\n",
    "        indexes = np.in1d(terms_indexes[topic], np.array(q)).nonzero()[0]\n",
    "\n",
    "        if len(indexes)==0:\n",
    "            probas_c_q[i] = 0\n",
    "        else:\n",
    "            p_q_c = D[topic].tocsc()[indexes]/D[topic].tocsc().sum()\n",
    "            p_q_c = p_q_c.toarray()\n",
    "            probas_c_q[i] = p_c * np.product(p_q_c)\n",
    "            \n",
    "    df = pd.read_csv(f'./Data/all.csv')\n",
    "    df.columns = [\"id\", \"titre\", \"contenu\", \"liens\"]\n",
    "            \n",
    "    docs = df[df[\"titre\"].isin(docs_index)]\n",
    "    \n",
    "    # print(docs)\n",
    "    \n",
    "    docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n",
    "    \n",
    "    # print(docs)\n",
    "\n",
    "    # garder les 3 meilleurs cj\n",
    "    # sorted_indices = np.argsort(-probas_c_q)\n",
    "    # \n",
    "    # top_indices = sorted_indices[:3]\n",
    "    # top_values = probas_c_q[top_indices]\n",
    "    # \n",
    "    # # somme des P(cj|q) * rank j\n",
    "    # res = 0\n",
    "    # for i in range(3):\n",
    "    #     res+= top_values[i]*topic_pagerank[Topic_names[top_indices[i]]]\n",
    "    #return np.sum(top_values*topic_pagerank[top_indices],axis=1)\n",
    "\n",
    "\n",
    "    # meilleurs documents :\n",
    "\n",
    "    # doc qui ont les mots de la query sans pyterrier\n",
    "    # df['text_lower'] = df['contenu'].str.lower() # Convert the text column to lowercase for case-insensitive search\n",
    "    # query_words = q.lower().split() # Split the query into individual words\n",
    "    # mask = df['text_lower'].str.contains('|'.join(query_words)) # boolean mask to filter rows containing any of the query words\n",
    "    # doc_indices = df.index[mask] # indices des docs qui ont la query\n",
    "    \n",
    "    #res[doc_indices]+=100 # on leur donne plus de valeur pour qu'ils sortent d'abord\n",
    "\n",
    "    #sorted_docs_index = np.argsort(-res)\n",
    "    # best_docs = pd.read_csv(f'./Data/all.csv')[\"titre\"].values[sorted_docs_index]\n",
    "\n",
    "    best_docs = docs.sort_values(by=\"score\", ascending=False)[\"titre\"]\n",
    "    return best_docs"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:24:55.361183Z",
     "start_time": "2024-05-21T22:24:53.298783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# query = \"affirmative action\"\n",
    "# print(sqd(query, topic_pagerank, D, terms_indexes, index)[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8        Expressive therapies\n",
      "11499        Apple and unions\n",
      "12423           Shadow family\n",
      "12384           Public sphere\n",
      "12357    Gender mainstreaming\n",
      "Name: titre, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:31:47.585703Z",
     "start_time": "2024-05-21T22:31:47.578915Z"
    }
   },
   "source": [
    "def score_normal_pagerank(q,normal_pagerank):\n",
    "    \n",
    "    # # doc qui ont les mots de la query (sans pyterrier)\n",
    "    # df['text_lower'] = df['contenu'].str.lower() # Convert the text column to lowercase for case-insensitive search\n",
    "    # query_words = q.lower().split() # Split the query into individual words\n",
    "    # mask = df['text_lower'].str.contains('|'.join(query_words)) # boolean mask to filter rows containing any of the query words\n",
    "    # doc_indices = df.index[mask] # indices des docs qui ont la query\n",
    "    # normal_pagerank[doc_indices] +=100\n",
    "    # \n",
    "    # sorted_docs_index = np.argsort(-normal_pagerank)\n",
    "    # best_docs = pd.read_csv(f'./Data/all.csv')[\"titre\"].values[sorted_docs_index]\n",
    "    \n",
    "    # Using a text index, recuperer les docs qui contiennent q\n",
    "    br = pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\") # CoordinateMatch renvoie 1 si le terme est dans le doc, 0 sinon\n",
    "    docs_retrieved = br.search(q) # Renvoie le nombre de termes de la query qui sont dans chaque doc\n",
    "    docs_query = docs_retrieved[docs_retrieved[\"score\"] == len(q.split())]  # Garder uniquement les docs qui contiennent tous les termes de la query\n",
    "    sorted_index = docs_query[\"docno\"].values\n",
    "    \n",
    "    df = pd.read_csv(f'./Data/all.csv')\n",
    "    df.columns = [\"id\", \"titre\", \"contenu\", \"liens\"]\n",
    "    \n",
    "    docs = df[df[\"titre\"].isin(sorted_index)]\n",
    "    docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
    "    \n",
    "    best_docs = docs.sort_values(by=\"score\", ascending=False)[\"titre\"]\n",
    "    \n",
    "    return best_docs\n"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity ranking (4.1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:25:03.316252Z",
     "start_time": "2024-05-21T22:25:03.302687Z"
    }
   },
   "source": [
    "def OSim(t1, t2, n=20):\n",
    "    # t1, t2 listes\n",
    "    return len(set(t1[:n])&set(t2[:n]))/n"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:25:03.747276Z",
     "start_time": "2024-05-21T22:25:03.741410Z"
    }
   },
   "source": [
    "import itertools\n",
    "\n",
    "def KSim(t1, t2):\n",
    "    # t1, t2 listes\n",
    "    U = set(t1)|set(t2)\n",
    "    delta1 = U - set(t1)\n",
    "    delta2 = U - set(t2)\n",
    "    t1_prime = t1+list(delta1)\n",
    "    t2_prime = t1+list(delta2)\n",
    "    sim = 0\n",
    "    for u,v in list(itertools.permutations(U, 2)):\n",
    "        if np.sign(t1_prime.index(u)-t1_prime.index(v))==np.sign(t2_prime.index(u)-t2_prime.index(v)):\n",
    "            sim+=1\n",
    "    return sim/(len(U)*(len(U)-1))\n"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests on queries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:25:05.163632Z",
     "start_time": "2024-05-21T22:25:05.144329Z"
    }
   },
   "source": [
    "queries = [ \"affirmative action\", \"alcoholism\", \"amusement parks\", \n",
    "            \"architecture\", \"bicycling\", \"blues\", \"cheese\", \n",
    "            \"citrus groves\", \"classical guitar\", \"computer vision\", \n",
    "            \"cruises\", \"death valley\", \"field hockey\", \n",
    "            \"gardening\", \"graphic design\", \"gulf war\", \n",
    "            \"hiv\", \"java\", \"lipari\",\n",
    "            \"lyme disease\", \"mutual funds\", \"national parks\", \n",
    "            \"parallel architecture\", \"recycling cans\", \"rock climbing\", \n",
    "            \"san francisco\", \"shakespeare\", \"stamp collecting\", \n",
    "            \"sushi\", \"table tennis\", \"telecommuting\", \n",
    "            \"vintage cars\", \"volcano\", \"zen buddhism\", \"zener\"]"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:25:06.840658Z",
     "start_time": "2024-05-21T22:25:06.495049Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "with open(\"terms_indexes.pkl\", \"rb\") as f:\n",
    "    terms_indexes = pickle.load(f)\n",
    "with open(\"D.pkl\", \"rb\") as f:\n",
    "    D = pickle.load(f)\n",
    "    for topic in Topic_names:\n",
    "        D[topic] = np.reshape(D[topic],(D[topic].shape[1],1))\n",
    "with open(\"topic_pagerank.pkl\", \"rb\") as f:\n",
    "    topic_pagerank = pickle.load(f)\n",
    "    \n",
    "index = pt.IndexFactory.of(\"./pd_index\")"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:25:16.089366Z",
     "start_time": "2024-05-21T22:25:07.666537Z"
    }
   },
   "source": [
    "for q in queries[:5]:\n",
    "    print(q)\n",
    "    print(sqd(q, topic_pagerank, D, terms_indexes, index)[:5])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affirmative action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/3286053638.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  print(sqd(q, topic_pagerank, D, terms_indexes, index)[:5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8        Expressive therapies\n",
      "11499        Apple and unions\n",
      "12423           Shadow family\n",
      "12384           Public sphere\n",
      "12357    Gender mainstreaming\n",
      "Name: titre, dtype: object\n",
      "alcoholism\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15584           Shameless (British TV series)\n",
      "13729                     I will moida da bum\n",
      "8276                 Violence and video games\n",
      "5827                      Million Women Study\n",
      "10992    List of Stargate Universe characters\n",
      "Name: titre, dtype: object\n",
      "amusement parks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/3286053638.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  print(sqd(q, topic_pagerank, D, terms_indexes, index)[:5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85         Dream world (plot device)\n",
      "8879                            Park\n",
      "8762                         Soarin'\n",
      "8758    Lists of tourist attractions\n",
      "8743              Tourist attraction\n",
      "Name: titre, dtype: object\n",
      "architecture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/3286053638.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  print(sqd(q, topic_pagerank, D, terms_indexes, index)[:5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750                          Art\n",
      "8750                      Museum\n",
      "10584      Mapping controversies\n",
      "12584    Heritage interpretation\n",
      "5584         Imaging informatics\n",
      "Name: titre, dtype: object\n",
      "bicycling\n",
      "6273                                        Pannier\n",
      "758                                  Conceptual art\n",
      "2827                                          Intel\n",
      "14841               Global Alliance for EcoMobility\n",
      "4843     List of Colorado geographic features lists\n",
      "Name: titre, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:31:15.326280Z",
     "start_time": "2024-05-21T22:31:15.311308Z"
    }
   },
   "source": [
    "with open(\"normal_pagerank.pkl\", \"rb\") as f:\n",
    "        normal_pagerank = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:32:04.168547Z",
     "start_time": "2024-05-21T22:31:55.907965Z"
    }
   },
   "source": [
    "for q in queries[:5]:\n",
    "    print(q)\n",
    "    print(score_normal_pagerank(q, normal_pagerank)[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affirmative action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14017    Universal Declaration of Human Rights\n",
      "10992     List of Stargate Universe characters\n",
      "7810                           Murray Rothbard\n",
      "14841          Global Alliance for EcoMobility\n",
      "7101                               Jactitation\n",
      "Name: titre, dtype: object\n",
      "alcoholism\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15584    Shameless (British TV series)\n",
      "13729              I will moida da bum\n",
      "5827               Million Women Study\n",
      "8276          Violence and video games\n",
      "6156                      Chafing dish\n",
      "Name: titre, dtype: object\n",
      "amusement parks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8584                            Hobby\n",
      "8758     Lists of tourist attractions\n",
      "14148                       Ice cream\n",
      "7748              Japanese war crimes\n",
      "10994                 Kenny McCormick\n",
      "Name: titre, dtype: object\n",
      "architecture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750                          Art\n",
      "8750                      Museum\n",
      "12584    Heritage interpretation\n",
      "10584      Mapping controversies\n",
      "5584         Imaging informatics\n",
      "Name: titre, dtype: object\n",
      "bicycling\n",
      "6273                                        Pannier\n",
      "758                                  Conceptual art\n",
      "2827                                          Intel\n",
      "14841               Global Alliance for EcoMobility\n",
      "4843     List of Colorado geographic features lists\n",
      "Name: titre, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:32:53.790483Z",
     "start_time": "2024-05-21T22:32:44.860126Z"
    }
   },
   "source": [
    "for q in queries[:5]:\n",
    "    print(q)\n",
    "    print(score_normal_pagerank(q, topic_pagerank['business'])[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affirmative action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10992     List of Stargate Universe characters\n",
      "14017    Universal Declaration of Human Rights\n",
      "9991          Chronicle of the King D. Pedro I\n",
      "7101                               Jactitation\n",
      "748                              Theory of art\n",
      "Name: titre, dtype: object\n",
      "alcoholism\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6922                                   Skewer\n",
      "12922                            Public enemy\n",
      "11958                                  Sandoz\n",
      "8969                               Maxim Wien\n",
      "10992    List of Stargate Universe characters\n",
      "Name: titre, dtype: object\n",
      "amusement parks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10958                          Tom Swift\n",
      "8136               Video games and Linux\n",
      "3996     Characters of the Tekken series\n",
      "8758        Lists of tourist attractions\n",
      "10994                    Kenny McCormick\n",
      "Name: titre, dtype: object\n",
      "architecture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8962                                 Reserve design\n",
      "969                                          Design\n",
      "272                                       Patronage\n",
      "3272    List of Xbox games compatible with Xbox 360\n",
      "8750                                         Museum\n",
      "Name: titre, dtype: object\n",
      "bicycling\n",
      "2827                      Intel\n",
      "13955          Element (sports)\n",
      "8109         Humans vs. Zombies\n",
      "6273                    Pannier\n",
      "9302     Guinness World Records\n",
      "Name: titre, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:26:10.157525Z",
     "start_time": "2024-05-21T22:26:10.122238Z"
    }
   },
   "source": [
    "for q in queries[:5]:\n",
    "    print(q)\n",
    "    print(score_normal_pagerank(q, topic_pagerank['sports'])[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affirmative action\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'contenu'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3789\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3790\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3791\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'contenu'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m queries[:\u001B[38;5;241m5\u001B[39m]:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(q)\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mscore_normal_pagerank\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopic_pagerank\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msports\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m[:\u001B[38;5;241m5\u001B[39m])\n",
      "Cell \u001B[0;32mIn[68], line 4\u001B[0m, in \u001B[0;36mscore_normal_pagerank\u001B[0;34m(q, normal_pagerank)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscore_normal_pagerank\u001B[39m(q,normal_pagerank):\n\u001B[1;32m      2\u001B[0m     \n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# doc qui ont les mots de la query (sans pyterrier)\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext_lower\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontenu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;66;03m# Convert the text column to lowercase for case-insensitive search\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     query_words \u001B[38;5;241m=\u001B[39m q\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39msplit() \u001B[38;5;66;03m# Split the query into individual words\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     mask \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext_lower\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mcontains(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(query_words)) \u001B[38;5;66;03m# boolean mask to filter rows containing any of the query words\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3893\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3895\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3792\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3793\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3794\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3795\u001B[0m     ):\n\u001B[1;32m   3796\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3797\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3798\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3799\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3800\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3801\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3802\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'contenu'"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarité entre les ranking de pagerank normal et de pagerank avec topic"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:35:22.372767Z",
     "start_time": "2024-05-21T22:33:25.381810Z"
    }
   },
   "source": [
    "for q in queries:\n",
    "    normal = score_normal_pagerank(q, normal_pagerank)\n",
    "    topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
    "    print(q,\"\\tOSim:\",OSim(normal, topic, n=20))\n",
    "    #print(\"KSim,\",KSim(normal[:20], topic[:20]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affirmative action \tOSim: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcoholism \tOSim: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amusement parks \tOSim: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture \tOSim: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycling \tOSim: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blues \tOSim: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheese \tOSim: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citrus groves \tOSim: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical guitar \tOSim: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer vision \tOSim: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruises \tOSim: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "death valley \tOSim: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field hockey \tOSim: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gardening \tOSim: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphic design \tOSim: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gulf war \tOSim: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiv \tOSim: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java \tOSim: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lipari \tOSim: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lyme disease \tOSim: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mutual funds \tOSim: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national parks \tOSim: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel architecture \tOSim: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recycling cans \tOSim: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock climbing \tOSim: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "san francisco \tOSim: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare \tOSim: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stamp collecting \tOSim: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sushi \tOSim: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table tennis \tOSim: 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telecommuting \tOSim: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vintage cars \tOSim: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volcano \tOSim: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zen buddhism \tOSim: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/2442772345.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = normal_pagerank[docs[\"id\"].values]\n",
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/1566747647.py:3: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  topic = sqd(q, topic_pagerank, D, terms_indexes, index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zener \tOSim: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_15530/4254619777.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  docs[\"score\"] = docs.apply(lambda x: sum([probas_c_q[Topic_names.index(topic)]*topic_pagerank[topic][x[\"id\"]] for topic in Topic_names]), axis=1)\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
