{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire : \n",
    "- contruire le graphe\n",
    "- changer les noms des fichiers json pour qu'ils soient appelés par leur titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "    user_agent='MyProjectName',\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get links for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def url_categorymembers(categorymembers,list_pages=[], level=0, max_level=1, i=0):\n",
    "    pages_cat = list(categorymembers.values()) #toutes les pages de la catégorie\n",
    "\n",
    "    shuffle(pages_cat)\n",
    "\n",
    "    for c in pages_cat:\n",
    "        if i==1000: #1000 pages par catégorie\n",
    "            break\n",
    "\n",
    "        if c.title[:6]!=\"Portal\" and c.title[:8]!=\"Category\": # vérifie que c'est bien un article\n",
    "            i+=1\n",
    "            #list_urls.append(c.fullurl)\n",
    "            #print(c.title)\n",
    "            #list_pages.append(c)\n",
    "            list_pages.append(c.title)\n",
    "\n",
    "        if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level: # descend d'un niveau\n",
    "            i = url_categorymembers(c.categorymembers, list_pages, level=level + 1, max_level=max_level, i=i)[1]\n",
    "\n",
    "    return list_pages, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_arts = wiki_wiki.page(\"Category:The arts\") # Arts\n",
    "arts, _ = url_categorymembers(cat_arts.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_games = wiki_wiki.page(\"Category:Games\") # Games\n",
    "games, _= url_categorymembers(cat_games.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_youth = wiki_wiki.page(\"Category:Youth\") # Kids and Teens (not exact)\n",
    "youth, _ = url_categorymembers(cat_youth.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_reference = wiki_wiki.page(\"Category:Reference\") # Reference\n",
    "reference, _ = url_categorymembers(cat_reference.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_shopping = wiki_wiki.page(\"Category:Shopping (activity)\") # Shopping\n",
    "shopping, _ = url_categorymembers(cat_shopping.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_business = wiki_wiki.page(\"Category:Business\") # Business\n",
    "business, _ = url_categorymembers(cat_business.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_health = wiki_wiki.page(\"Category:Health\") # Health\n",
    "health, _ = url_categorymembers(cat_health.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_news = wiki_wiki.page(\"Category:News\") # News\n",
    "news, _ = url_categorymembers(cat_news.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_geography = wiki_wiki.page(\"Category:Geography\") # Regional (not exact)\n",
    "geography, _ = url_categorymembers(cat_geography.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_society = wiki_wiki.page(\"Category:Society\") # Society\n",
    "society, _ = url_categorymembers(cat_society.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_computers = wiki_wiki.page(\"Category:Computers\") # Computers\n",
    "computers, _ = url_categorymembers(cat_computers.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_home = wiki_wiki.page(\"Category:Home\") # Home\n",
    "home, _ = url_categorymembers(cat_home.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_recreation = wiki_wiki.page(\"Category:Recreation\") # Recreation\n",
    "recreation, _ = url_categorymembers(cat_recreation.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_science = wiki_wiki.page(\"Category:Science\") # Science\n",
    "science, _ = url_categorymembers(cat_science.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sports = wiki_wiki.page(\"Category:Sports\") # Sports\n",
    "sports, _ = url_categorymembers(cat_sports.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_world = wiki_wiki.page(\"Category:World\") # World\n",
    "world, _ = url_categorymembers(cat_world.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    \"Arts\": arts,\n",
    "    \"Games\": games,\n",
    "    \"Youth\": youth,\n",
    "    \"Reference\": reference, \n",
    "    \"Shopping\": shopping, \n",
    "    \"Business\": business, \n",
    "    \"Health\": health, \n",
    "    \"News\": news,\n",
    "    \"Geography\": geography,\n",
    "    \"Society\": society,\n",
    "    \"Computers\": computers,\n",
    "    \"Home\": home,\n",
    "    \"Recreation\": recreation,\n",
    "    \"Science\": science,\n",
    "    \"Sports\": sports,\n",
    "    \"World\": world\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Page Rank vectors (3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "# extract links from a Wikipedia page\n",
    "def page_links(page):\n",
    "        links = page.links\n",
    "        links2 = []\n",
    "        for p in links.values():\n",
    "            try:\n",
    "                url = p.fullurl\n",
    "            except:\n",
    "                url = None\n",
    "            if url is not None:\n",
    "                links2.append(url)\n",
    "        return links2\n",
    "\n",
    "# build the adjacency matrix\n",
    "def build_adjacency_matrix(urls, pages):\n",
    "    num_pages = len(urls)\n",
    "    adjacency_matrix = np.zeros((num_pages, num_pages))\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        links = page_links(pages[i])\n",
    "        for link in links:\n",
    "            if link in urls:\n",
    "                j = urls.index(link)\n",
    "                adjacency_matrix[i][j] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\"\"\"\n",
    "\n",
    "# compute PageRank scores\n",
    "def compute_pagerank(M, alpha=0.25):\n",
    "    # M = adjacency_matrix\n",
    "    # damping_factor = 1-alpha\n",
    "    N = M.shape[0]\n",
    "    teleportation_matrix = np.ones((N, N)) / N\n",
    "\n",
    "    M_prime = (1-alpha) * M + alpha * teleportation_matrix\n",
    "\n",
    "    rank = np.ones(N) / N\n",
    "    old_rank = np.zeros(N)\n",
    "\n",
    "    epsilon = 1.0e-6\n",
    "    max_iterations = 100\n",
    "    iterations = 0\n",
    "\n",
    "    while np.sum(np.abs(rank - old_rank)) > epsilon and iterations < max_iterations:\n",
    "        old_rank = rank.copy()\n",
    "        rank = np.dot(M_prime, rank)\n",
    "        iterations += 1\n",
    "\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PageRank scores for each topic\n",
    "\n",
    "topic_pagerank = {}\n",
    "for topic, (urls, pages) in topics.items():\n",
    "    adjacency_matrix = build_adjacency_matrix(urls, pages)\n",
    "    pagerank_scores = compute_pagerank(adjacency_matrix)\n",
    "    topic_pagerank[topic] = pagerank_scores\n",
    "\n",
    "# Print PageRank scores for each topic\n",
    "for topic, scores in topic_pagerank.items():\n",
    "    print(f\"Topic: {topic}\")\n",
    "    for url, score in zip(topics[topic], scores):\n",
    "        print(f\"{url}: {score}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity ranking (4.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSim(t1, t2, n=20):\n",
    "    # t1, t2 listes\n",
    "    return len(set(t1[:n])&set(t2[:n]))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def KSim(t1, t2):\n",
    "    # t1, t2 listes\n",
    "    U = set(t1)|set(t2)\n",
    "    delta1 = U - set(t1)\n",
    "    delta2 = U - set(t2)\n",
    "    t1_prime = t1+list(delta1)\n",
    "    t2_prime = t1+list(delta2)\n",
    "    sim = 0\n",
    "    for u,v in list(itertools.permutations(U, 2)):\n",
    "        if np.sign(t1_prime.index(u)-t1_prime.index(v))==np.sign(t2_prime.index(u)-t2_prime.index(v)):\n",
    "            sim+=1\n",
    "    return sim/(len(U)*(len(U)-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query-time importance score (3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire : changer le nom de fichiers json pour qu'ils soient enregistrés sous le nom de leur titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "categories_text = []\n",
    "for c in topics.keys():\n",
    "    text=\"\"\n",
    "    for article in topics[c]:\n",
    "        with open(f\"{article}.json\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            text+=\" \"+json_data.text\n",
    "        categories_text.append(text)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "D = vectorizer.fit_transform(categories_text)\n",
    "terms_indexes = vectorizer.get_feature_names_out()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqd(q, topic_pagerank, D, terms_indexes):\n",
    "    # D = gives the total number of occurrences of each term in each document, array of shape = classes x terms\n",
    "    \n",
    "    p_c = 1/16 # \"The quantity P(cj) is not as straightforward. We chose to make it uniform\n",
    "    \n",
    "    indexes = np.in1d(terms_indexes, np.array(q)).nonzero()[0]\n",
    "\n",
    "    p_q_c = D[indexes]/D.sum(axis=1)\n",
    "\n",
    "    probas_c_q = p_c * np.product(p_q_c)\n",
    "\n",
    "    return np.sum(probas_c_q*topic_pagerank,axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
