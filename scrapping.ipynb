{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "    user_agent='MyProjectName',\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get links for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def url_categorymembers(categorymembers, list_urls=[], list_pages=[], level=0, max_level=1):\n",
    "    pages_cat = list(categorymembers.values()) #toutes les pages de la catégorie\n",
    "\n",
    "    shuffle(pages_cat)\n",
    "\n",
    "    i = 0 # nb de pages\n",
    "\n",
    "    for c in pages_cat:\n",
    "        if i==1000: #1000 pages par catégorie\n",
    "            break\n",
    "\n",
    "        if c.title[:6]!=\"Portal\" and c.title[:8]!=\"Category\": # vérifie que c'est bien un article\n",
    "            i+=1\n",
    "            list_urls.append(c.fullurl)\n",
    "            print(c.title)\n",
    "            list_pages.append(c)\n",
    "\n",
    "        if c.ns == wikipediaapi.Namespace.CATEGORY and level < max_level: # descend d'un niveau\n",
    "            url_categorymembers(c.categorymembers, list_urls, list_pages, level=level + 1, max_level=max_level)\n",
    "\n",
    "    return list_urls, list_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warli\n",
      "Indian art\n",
      "Mangaung African Cultural Festival\n",
      "International Sculpture Day\n",
      "Resistencia Biennial International Sculptures Contest\n",
      "V&A Digital Futures\n",
      "Bus-Tops\n",
      "Happening\n",
      "Yota Space\n",
      "EU Talent Day\n",
      "Sonoma State University\n",
      "Cork Caucus\n",
      "Columbus Invitational Arts Competition\n",
      "Computer art\n",
      "Showpiece\n",
      "Creative work\n",
      "Creative work\n",
      "Setting (narrative)\n",
      "Plagiarism\n",
      "Bibliotherapy\n",
      "Mabel Elsworth Todd\n",
      "Gabrielle Rifkind\n",
      "Authentic Movement\n",
      "Drama therapy\n",
      "Expressive therapies\n",
      "Psychodrama\n",
      "Cinema therapy\n",
      "Transformative arts\n",
      "Art therapy\n",
      "Dance therapy\n",
      "Diorama Arts Cooperative\n",
      "Gifted art\n",
      "Impact of the COVID-19 pandemic on the performing arts\n",
      "Ireland's Great Hunger Museum\n",
      "Smoky Mountain Opry Theater\n",
      "The Parsonage Garden at Nuenen\n",
      "Artist Relief\n",
      "Liliesleaf Farm\n",
      "Impact of the COVID-19 pandemic on the arts and cultural heritage\n",
      "La Colonie (Art Space)\n",
      "Information art\n",
      "List of works by Charles-Auguste Lebourg\n",
      "List of knitting stitches\n",
      "List of Bunnykins figurines\n",
      "List of works by Gian Lorenzo Bernini\n",
      "Chess in the arts\n",
      "List of Lalit Kala Akademi fellows\n",
      "The arts\n",
      "List of art dealers\n",
      "List of art media\n",
      "List of works by Michelangelo\n",
      "List of cultural conservation and restoration organizations\n",
      "List of Creative Capital grant recipients\n",
      "Outline of painting\n",
      "List of blackface minstrel troupes\n",
      "Decorative knot\n",
      "List of works with different titles in the United Kingdom and United States\n",
      "Artist\n",
      "Index of articles related to sound art\n",
      "Outline of sculpture\n",
      "Index of color-related articles\n",
      "List of contemporary art museums\n",
      "Outline of performing arts\n",
      "List of African-American arts firsts\n",
      "List of United States airmail stamps\n",
      "List of IATSE locals\n",
      "List of works about Rembrandt\n",
      "Women in the art history field\n",
      "List of depictions of urine in art\n",
      "List of exhibitions by Olafur Eliasson\n",
      "Libro de' Disegni\n",
      "Pinacoteca Civica Fortunato Duranti\n",
      "List of art magazines\n",
      "List of koans by Yunmen Wenyan\n",
      "List of canonically crowned images\n",
      "Migrantas\n",
      "List of Royal Doulton figurines\n",
      "List of Independent Curators International exhibitions\n",
      "List of works by De Es Schwertberger\n",
      "List of members of the European Academy of Sciences and Arts\n",
      "Works based on a copyright-free Mickey Mouse\n",
      "List of works set within one day\n",
      "List of artworks in the collection of the Royal Society of Chemistry\n",
      "Outline of photography\n",
      "World premieres at the Edinburgh International Festival\n",
      "List of key works of Carolingian illumination\n",
      "Greek and Latin metre\n",
      "List of invisible artworks\n",
      "List of art looted by Napoleonic armies\n",
      "List of California Institute of the Arts people\n",
      "List of Stranger Genius Awards winners\n",
      "List of French artistic movements\n",
      "List of washi\n",
      "List of artworks known in English by a foreign title\n",
      "Stephen Fry bibliography and filmography\n",
      "List of hairstyles\n",
      "Fine art\n",
      "Creative class\n",
      "Intellectual property\n",
      "New Music Economy\n",
      "Cultural subsidy\n",
      "Remember To Rise\n",
      "Media imperialism\n",
      "Economics of the arts and literature\n",
      "Noise: The Political Economy of Music\n",
      "Film industry\n",
      "CETA Employment of Artists (1974-1981)\n",
      "Video game industry\n",
      "International trade in fine art\n",
      "Press support\n",
      "Media economics\n",
      "Creative industries\n",
      "Payola\n",
      "Creative industry in Brazil\n",
      "Oindrilla Maity Surai\n",
      "Pastiche\n",
      "Social practice\n",
      "West Midtown\n",
      "Greenwich Village\n",
      "Lodhi Art District\n",
      "Bang Rak subdistrict\n",
      "Ludlow Street (Manhattan)\n",
      "Uptown Oakland\n",
      "Village of the Arts\n",
      "Castleberry Hill\n",
      "NoDa (Charlotte neighborhood)\n",
      "Midtown Atlanta\n",
      "NoHo Arts District, Los Angeles\n",
      "Arts District, Richmond, Virginia\n",
      "San Pablo Arts District\n",
      "Avenue of the Arts (Philadelphia)\n",
      "Leather and LGBTQ Cultural District\n",
      "Broad Avenue\n",
      "Wynwood Art District\n",
      "Paseo Arts District\n",
      "Arts District, Bakersfield\n",
      "798 Art Zone\n",
      "Arts District, Dallas\n",
      "Crossroads, Kansas City\n",
      "Santa Fe Railyard\n",
      "Trinity Buoy Wharf\n",
      "Neighborhoods of Tulsa, Oklahoma\n",
      "Four Denominations District\n",
      "South Main Arts District, Memphis\n",
      "Downtown Bakersfield\n",
      "Bromo Arts District\n",
      "Highlandtown Arts District, Baltimore, MD\n",
      "North Village Arts District\n",
      "Arts District (Honolulu)\n",
      "Ray Street Arts District\n",
      "River North Gallery District, Near North Side, Chicago\n",
      "Bishop Arts District, Dallas\n",
      "Oregon Historic District\n",
      "Powerhouse Arts District, Jersey City\n",
      "Crossroads, Kansas City\n",
      "Station North Arts and Entertainment District\n",
      "Arts District (Portland, Maine)\n",
      "Hohenzollernstraße\n",
      "Dumbo, Brooklyn\n",
      "Arts District, Oklahoma City\n",
      "Vila Madalena\n",
      "Denver's Art District on Santa Fe\n",
      "Queen Street Arts and Culture District\n",
      "Cathedral Quarter, Belfast\n",
      "East Village, Manhattan\n",
      "Benjamin Franklin Parkway\n",
      "Brooklyn Cultural District\n",
      "East Village, Long Beach, California\n",
      "18b The Las Vegas Arts District\n",
      "Arts District, Los Angeles\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cat_arts \u001b[38;5;241m=\u001b[39m wiki_wiki\u001b[38;5;241m.\u001b[39mpage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory:The arts\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Arts\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m arts, arts_pages \u001b[38;5;241m=\u001b[39m url_categorymembers(cat_arts\u001b[38;5;241m.\u001b[39mcategorymembers)\n",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m, in \u001b[0;36murl_categorymembers\u001b[1;34m(categorymembers, list_urls, list_pages, level, max_level)\u001b[0m\n\u001b[0;32m     18\u001b[0m         list_pages\u001b[38;5;241m.\u001b[39mappend(c)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mns \u001b[38;5;241m==\u001b[39m wikipediaapi\u001b[38;5;241m.\u001b[39mNamespace\u001b[38;5;241m.\u001b[39mCATEGORY \u001b[38;5;129;01mand\u001b[39;00m level \u001b[38;5;241m<\u001b[39m max_level: \u001b[38;5;66;03m# descend d'un niveau\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m         url_categorymembers(c\u001b[38;5;241m.\u001b[39mcategorymembers, list_urls, list_pages, level\u001b[38;5;241m=\u001b[39mlevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_level\u001b[38;5;241m=\u001b[39mmax_level)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m list_urls, list_pages\n",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m, in \u001b[0;36murl_categorymembers\u001b[1;34m(categorymembers, list_urls, list_pages, level, max_level)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mtitle[:\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPortal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m c\u001b[38;5;241m.\u001b[39mtitle[:\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;66;03m# vérifie que c'est bien un article\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 16\u001b[0m     list_urls\u001b[38;5;241m.\u001b[39mappend(c\u001b[38;5;241m.\u001b[39mfullurl)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c\u001b[38;5;241m.\u001b[39mtitle)\n\u001b[0;32m     18\u001b[0m     list_pages\u001b[38;5;241m.\u001b[39mappend(c)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\wikipediaapi\\__init__.py:874\u001b[0m, in \u001b[0;36mWikipediaPage.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m call \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mATTRIBUTES_MAPPING[name]:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_called[call]:\n\u001b[1;32m--> 874\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch(call)\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attributes[name]\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\wikipediaapi\\__init__.py:1064\u001b[0m, in \u001b[0;36mWikipediaPage._fetch\u001b[1;34m(self, call)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, call) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWikipediaPage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fetches some data?.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwiki, call)(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_called[call] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\wikipediaapi\\__init__.py:332\u001b[0m, in \u001b[0;36mWikipedia.info\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03mhttps://www.mediawiki.org/w/api.php?action=help&modules=query%2Binfo\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03mhttps://www.mediawiki.org/wiki/API:Info\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    312\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprop\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     ),\n\u001b[0;32m    331\u001b[0m }\n\u001b[1;32m--> 332\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(page, params)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_attributes(raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m], page)\n\u001b[0;32m    334\u001b[0m pages \u001b[38;5;241m=\u001b[39m raw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\wikipediaapi\\__init__.py:528\u001b[0m, in \u001b[0;36mWikipedia._query\u001b[1;34m(self, page, params)\u001b[0m\n\u001b[0;32m    526\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mredirects\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 528\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mget(base_url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_kwargs)\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cat_arts = wiki_wiki.page(\"Category:The arts\") # Arts\n",
    "arts, arts_pages = url_categorymembers(cat_arts.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_games = wiki_wiki.page(\"Category:Games\") # Games\n",
    "games, games_pages = url_categorymembers(cat_games.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_youth = wiki_wiki.page(\"Category:Youth\") # Kids and Teens (not exact)\n",
    "youth, youth_pages = url_categorymembers(cat_youth.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_reference = wiki_wiki.page(\"Category:Reference\") # Reference\n",
    "reference, reference_pages = url_categorymembers(cat_reference.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_shopping = wiki_wiki.page(\"Category:Shopping (activity)\") # Shopping\n",
    "shopping, shopping_pages = url_categorymembers(cat_shopping.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_business = wiki_wiki.page(\"Category:Business\") # Business\n",
    "business, business_pages = url_categorymembers(cat_business.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_health = wiki_wiki.page(\"Category:Health\") # Health\n",
    "health, health_pages = url_categorymembers(cat_health.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_news = wiki_wiki.page(\"Category:News\") # News\n",
    "news, news_pages = url_categorymembers(cat_news.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_geography = wiki_wiki.page(\"Category:Geography\") # Regional (not exact)\n",
    "geography, geography_pages = url_categorymembers(cat_geography.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_society = wiki_wiki.page(\"Category:Society\") # Society\n",
    "society, society_pages = url_categorymembers(cat_society.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_computers = wiki_wiki.page(\"Category:Computers\") # Computers\n",
    "computers, computers_pages = url_categorymembers(cat_computers.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_home = wiki_wiki.page(\"Category:Home\") # Home\n",
    "home, home_pages = url_categorymembers(cat_home.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_recreation = wiki_wiki.page(\"Category:Recreation\") # Recreation\n",
    "recreation, recreation_pages = url_categorymembers(cat_recreation.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_science = wiki_wiki.page(\"Category:Science\") # Science\n",
    "science, science_pages = url_categorymembers(cat_science.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sports = wiki_wiki.page(\"Category:Sports\") # Sports\n",
    "sports, sports_pages = url_categorymembers(cat_sports.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_world = wiki_wiki.page(\"Category:World\") # World\n",
    "world, world_pages = url_categorymembers(cat_world.categorymembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    \"Arts\": (arts, arts_pages),\n",
    "    \"Games\": (games, games_pages),\n",
    "    \"Youth\": (youth, youth_pages),\n",
    "    \"Reference\": (reference, reference_pages),\n",
    "    \"Shopping\": (shopping, shopping_pages),\n",
    "    \"Business\": (business, business_pages),\n",
    "    \"Health\": (health, health_pages),\n",
    "    \"News\": (news, news_pages),\n",
    "    \"Geography\": (geography, geography_pages),\n",
    "    \"Society\": (society, society_pages),\n",
    "    \"Computers\": (computers, computers_pages),\n",
    "    \"Home\": (home, home_pages),\n",
    "    \"Recreation\": (recreation, recreation_pages),\n",
    "    \"Science\": (science, science_pages),\n",
    "    \"Sports\": (sports, sports_pages),\n",
    "    \"World\": (world, world_pages)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Page Rank vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# extract links from a Wikipedia page\n",
    "def page_links(page):\n",
    "        links = page.links\n",
    "        links2 = []\n",
    "        for p in links.values():\n",
    "            try:\n",
    "                url = p.fullurl\n",
    "            except:\n",
    "                url = None\n",
    "            if url is not None:\n",
    "                links2.append(url)\n",
    "        return links2\n",
    "\n",
    "# build the adjacency matrix\n",
    "def build_adjacency_matrix(urls, pages):\n",
    "    num_pages = len(urls)\n",
    "    adjacency_matrix = np.zeros((num_pages, num_pages))\n",
    "\n",
    "    for i, url in enumerate(urls):\n",
    "        links = page_links(pages[i])\n",
    "        for link in links:\n",
    "            if link in urls:\n",
    "                j = urls.index(link)\n",
    "                adjacency_matrix[i][j] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "# compute PageRank scores\n",
    "def compute_pagerank(M, damping_factor=0.85):\n",
    "    # M = adjacency_matrix\n",
    "    # damping_factor = 1-alpha\n",
    "    N = M.shape[0]\n",
    "    teleportation_matrix = np.ones((N, N)) / N\n",
    "\n",
    "    M_prime = damping_factor * M + (1 - damping_factor) * teleportation_matrix\n",
    "\n",
    "    rank = np.ones(N) / N\n",
    "    old_rank = np.zeros(N)\n",
    "\n",
    "    epsilon = 1.0e-5\n",
    "    max_iterations = 100\n",
    "    iterations = 0\n",
    "\n",
    "    while np.sum(np.abs(rank - old_rank)) > epsilon and iterations < max_iterations:\n",
    "        old_rank = rank.copy()\n",
    "        rank = np.dot(M_prime, rank)\n",
    "        iterations += 1\n",
    "\n",
    "    return rank\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PageRank scores for each topic\n",
    "\n",
    "topic_pagerank = {}\n",
    "for topic, (urls, pages) in topics.items():\n",
    "    adjacency_matrix = build_adjacency_matrix(urls, pages)\n",
    "    pagerank_scores = compute_pagerank(adjacency_matrix)\n",
    "    topic_pagerank[topic] = pagerank_scores\n",
    "\n",
    "# Print PageRank scores for each topic\n",
    "for topic, scores in topic_pagerank.items():\n",
    "    print(f\"Topic: {topic}\")\n",
    "    for url, score in zip(topics[topic], scores):\n",
    "        print(f\"{url}: {score}\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
